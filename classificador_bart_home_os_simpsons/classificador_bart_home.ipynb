{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ccadbdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 7)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "base = pd.read_csv(\"personagens.csv\")\n",
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9a047411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laranja_camisa_bart</th>\n",
       "      <th>azul_calcao_bart</th>\n",
       "      <th>azul_sapato_bart</th>\n",
       "      <th>marrom_boca_homer</th>\n",
       "      <th>azul_calca_homer</th>\n",
       "      <th>cinza_sapato_homer</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.886102</td>\n",
       "      <td>3.495204</td>\n",
       "      <td>1.484984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.004901</td>\n",
       "      <td>3.183889</td>\n",
       "      <td>1.000142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033024</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.264620</td>\n",
       "      <td>5.029683</td>\n",
       "      <td>0.283567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151573</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.480168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021164</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.978929</td>\n",
       "      <td>3.459119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.485412</td>\n",
       "      <td>0.093921</td>\n",
       "      <td>Homer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042194</td>\n",
       "      <td>Homer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.263629</td>\n",
       "      <td>0.076761</td>\n",
       "      <td>Homer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.429134</td>\n",
       "      <td>0.017013</td>\n",
       "      <td>Homer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.744248</td>\n",
       "      <td>0.853902</td>\n",
       "      <td>0.063546</td>\n",
       "      <td>Homer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     laranja_camisa_bart  azul_calcao_bart  azul_sapato_bart  \\\n",
       "0               6.886102          3.495204          1.484984   \n",
       "1               5.004901          3.183889          1.000142   \n",
       "2               5.264620          5.029683          0.283567   \n",
       "3               0.000000          0.000000          0.000000   \n",
       "4               8.978929          3.459119          0.000000   \n",
       "..                   ...               ...               ...   \n",
       "288             0.000000          0.000000          0.000000   \n",
       "289             0.000000          0.000000          0.000000   \n",
       "290             0.000000          0.000000          0.000000   \n",
       "291             0.000000          0.000000          0.000000   \n",
       "292             0.000000          0.000000          0.000000   \n",
       "\n",
       "     marrom_boca_homer  azul_calca_homer  cinza_sapato_homer classe  \n",
       "0             0.000000          0.000000            0.062954   Bart  \n",
       "1             0.000000          0.000000            0.033024   Bart  \n",
       "2             0.000000          0.000000            0.151573   Bart  \n",
       "3             0.480168          0.000000            0.021164   Bart  \n",
       "4             0.000000          0.000000            0.011593   Bart  \n",
       "..                 ...               ...                 ...    ...  \n",
       "288           0.000000          6.485412            0.093921  Homer  \n",
       "289           0.000000          0.000000            0.042194  Homer  \n",
       "290           0.000000          4.263629            0.076761  Homer  \n",
       "291           0.000000          1.429134            0.017013  Homer  \n",
       "292          13.744248          0.853902            0.063546  Homer  \n",
       "\n",
       "[293 rows x 7 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.head(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87eb933",
   "metadata": {},
   "source": [
    "# SEPARANDO OS PREVISORES E A CLASSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6ba53812",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = base.iloc[:,:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0725203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 6)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a4e0fc76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart'\n",
      " 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Bart' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer'\n",
      " 'Homer' 'Homer' 'Homer' 'Homer' 'Homer' 'Homer']\n"
     ]
    }
   ],
   "source": [
    "classe = base.iloc[:, 6].values\n",
    "print(classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb065bb",
   "metadata": {},
   "source": [
    "## Aplicando o encoder nas classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "aedf727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lebalencoder = LabelEncoder()\n",
    "classes = lebalencoder.fit_transform(classe)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f92a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ff479c6",
   "metadata": {},
   "source": [
    "# SEPARANDO O DATASET DE TRAINAMENTO E TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0b2aa6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9d64a0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 6)\n",
      "(234,)\n",
      "(59, 6)\n",
      "(59,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(previsores,\n",
    "                                                    classes,\n",
    "                                                    test_size=0.20)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "837853dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1\n",
      " 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43247778",
   "metadata": {},
   "source": [
    "# Criando a rede Neural para classificaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "44fea2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0d41dc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 8)                 56        \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,833\n",
      "Trainable params: 1,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=8, activation=\"relu\", input_dim=6))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307001e",
   "metadata": {},
   "source": [
    "### Trainando a rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ad63bb3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 27ms/step - loss: 0.7004 - accuracy: 0.5296 - val_loss: 0.6591 - val_accuracy: 0.8136\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6645 - accuracy: 0.6821 - val_loss: 0.6189 - val_accuracy: 0.8475\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.6165 - accuracy: 0.7519 - val_loss: 0.5701 - val_accuracy: 0.8644\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5633 - accuracy: 0.8199 - val_loss: 0.5051 - val_accuracy: 0.8644\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5762 - accuracy: 0.7983 - val_loss: 0.4395 - val_accuracy: 0.8644\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.4732 - accuracy: 0.8378 - val_loss: 0.3723 - val_accuracy: 0.8644\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.4195 - accuracy: 0.8509 - val_loss: 0.3142 - val_accuracy: 0.8475\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3668 - accuracy: 0.8695 - val_loss: 0.2755 - val_accuracy: 0.8644\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8823 - val_loss: 0.2520 - val_accuracy: 0.8644\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2963 - accuracy: 0.9093 - val_loss: 0.2368 - val_accuracy: 0.8644\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3059 - accuracy: 0.8619 - val_loss: 0.2264 - val_accuracy: 0.8644\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2415 - accuracy: 0.9135 - val_loss: 0.2191 - val_accuracy: 0.8644\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2398 - accuracy: 0.9156 - val_loss: 0.2112 - val_accuracy: 0.8814\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2616 - accuracy: 0.8774 - val_loss: 0.2089 - val_accuracy: 0.8644\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2068 - accuracy: 0.9214 - val_loss: 0.2189 - val_accuracy: 0.8814\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1993 - accuracy: 0.9140 - val_loss: 0.2060 - val_accuracy: 0.8814\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2453 - accuracy: 0.8587 - val_loss: 0.2016 - val_accuracy: 0.8983\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2613 - accuracy: 0.8768 - val_loss: 0.2098 - val_accuracy: 0.8814\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1833 - accuracy: 0.9368 - val_loss: 0.2115 - val_accuracy: 0.8814\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2081 - accuracy: 0.9189 - val_loss: 0.2051 - val_accuracy: 0.8814\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2192 - accuracy: 0.9141 - val_loss: 0.2032 - val_accuracy: 0.8983\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2227 - accuracy: 0.9135 - val_loss: 0.2079 - val_accuracy: 0.8814\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1847 - accuracy: 0.9287 - val_loss: 0.2072 - val_accuracy: 0.8814\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1884 - accuracy: 0.9022 - val_loss: 0.1981 - val_accuracy: 0.8983\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1740 - accuracy: 0.9203 - val_loss: 0.2016 - val_accuracy: 0.8983\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2040 - accuracy: 0.9081 - val_loss: 0.2042 - val_accuracy: 0.8983\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2195 - accuracy: 0.8923 - val_loss: 0.2006 - val_accuracy: 0.8983\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1998 - accuracy: 0.9010 - val_loss: 0.2060 - val_accuracy: 0.8814\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2007 - accuracy: 0.8888 - val_loss: 0.2021 - val_accuracy: 0.8983\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1662 - accuracy: 0.9300 - val_loss: 0.1982 - val_accuracy: 0.8983\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.2220 - accuracy: 0.8739 - val_loss: 0.2013 - val_accuracy: 0.8983\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.2050 - accuracy: 0.9140 - val_loss: 0.2057 - val_accuracy: 0.8983\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1855 - accuracy: 0.9216 - val_loss: 0.2008 - val_accuracy: 0.8983\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1959 - accuracy: 0.9249 - val_loss: 0.2006 - val_accuracy: 0.8983\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1840 - accuracy: 0.8949 - val_loss: 0.1999 - val_accuracy: 0.8983\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1790 - accuracy: 0.9290 - val_loss: 0.1971 - val_accuracy: 0.8983\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1939 - accuracy: 0.8897 - val_loss: 0.2080 - val_accuracy: 0.8983\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1511 - accuracy: 0.9528 - val_loss: 0.2106 - val_accuracy: 0.8983\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1986 - accuracy: 0.8923 - val_loss: 0.2018 - val_accuracy: 0.8983\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1677 - accuracy: 0.9072 - val_loss: 0.1998 - val_accuracy: 0.8983\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1991 - accuracy: 0.8781 - val_loss: 0.2080 - val_accuracy: 0.8983\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1686 - accuracy: 0.9112 - val_loss: 0.2104 - val_accuracy: 0.8983\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1925 - accuracy: 0.9150 - val_loss: 0.2026 - val_accuracy: 0.8983\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1785 - accuracy: 0.9101 - val_loss: 0.1958 - val_accuracy: 0.8983\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.1633 - accuracy: 0.9179 - val_loss: 0.1986 - val_accuracy: 0.8983\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1648 - accuracy: 0.9418 - val_loss: 0.1985 - val_accuracy: 0.8983\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1555 - accuracy: 0.9296 - val_loss: 0.2006 - val_accuracy: 0.8983\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1845 - accuracy: 0.9050 - val_loss: 0.1990 - val_accuracy: 0.8983\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1819 - accuracy: 0.9199 - val_loss: 0.1996 - val_accuracy: 0.8983\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1759 - accuracy: 0.9162 - val_loss: 0.1931 - val_accuracy: 0.8983\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1628 - accuracy: 0.9207 - val_loss: 0.1956 - val_accuracy: 0.8983\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1943 - accuracy: 0.9138 - val_loss: 0.2046 - val_accuracy: 0.8983\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2343 - accuracy: 0.8666 - val_loss: 0.2036 - val_accuracy: 0.8983\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2142 - accuracy: 0.9156 - val_loss: 0.2105 - val_accuracy: 0.8983\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2006 - accuracy: 0.8951 - val_loss: 0.1968 - val_accuracy: 0.8983\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1858 - accuracy: 0.9149 - val_loss: 0.1989 - val_accuracy: 0.8983\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1886 - accuracy: 0.9371 - val_loss: 0.2049 - val_accuracy: 0.8983\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1388 - accuracy: 0.9485 - val_loss: 0.2022 - val_accuracy: 0.8983\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1598 - accuracy: 0.9110 - val_loss: 0.1989 - val_accuracy: 0.8983\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1727 - accuracy: 0.9185 - val_loss: 0.2009 - val_accuracy: 0.8983\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1657 - accuracy: 0.9318 - val_loss: 0.1966 - val_accuracy: 0.8983\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1623 - accuracy: 0.9283 - val_loss: 0.2012 - val_accuracy: 0.8983\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1988 - accuracy: 0.8950 - val_loss: 0.2054 - val_accuracy: 0.8983\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1715 - accuracy: 0.9405 - val_loss: 0.2036 - val_accuracy: 0.8983\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1754 - accuracy: 0.9063 - val_loss: 0.2039 - val_accuracy: 0.8983\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1644 - accuracy: 0.9270 - val_loss: 0.1998 - val_accuracy: 0.8814\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1608 - accuracy: 0.9177 - val_loss: 0.2027 - val_accuracy: 0.8983\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1812 - accuracy: 0.9163 - val_loss: 0.2047 - val_accuracy: 0.8983\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.9156 - val_loss: 0.2019 - val_accuracy: 0.8983\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1592 - accuracy: 0.9184 - val_loss: 0.2032 - val_accuracy: 0.8983\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1867 - accuracy: 0.9116 - val_loss: 0.2025 - val_accuracy: 0.8983\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1486 - accuracy: 0.9169 - val_loss: 0.1991 - val_accuracy: 0.8983\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1734 - accuracy: 0.9004 - val_loss: 0.2062 - val_accuracy: 0.8983\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.1794 - accuracy: 0.9134 - val_loss: 0.1990 - val_accuracy: 0.8983\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1340 - accuracy: 0.9510 - val_loss: 0.1980 - val_accuracy: 0.8814\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1744 - accuracy: 0.9216 - val_loss: 0.1958 - val_accuracy: 0.8983\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1831 - accuracy: 0.9114 - val_loss: 0.1969 - val_accuracy: 0.8814\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9426 - val_loss: 0.2057 - val_accuracy: 0.8983\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1714 - accuracy: 0.9222 - val_loss: 0.2011 - val_accuracy: 0.8814\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1815 - accuracy: 0.9060 - val_loss: 0.1987 - val_accuracy: 0.8983\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2009 - accuracy: 0.9281 - val_loss: 0.1984 - val_accuracy: 0.8814\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1543 - accuracy: 0.9274 - val_loss: 0.1992 - val_accuracy: 0.8983\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1562 - accuracy: 0.9236 - val_loss: 0.1938 - val_accuracy: 0.8814\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1662 - accuracy: 0.9350 - val_loss: 0.1920 - val_accuracy: 0.8814\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1565 - accuracy: 0.9300 - val_loss: 0.1942 - val_accuracy: 0.8983\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1485 - accuracy: 0.9243 - val_loss: 0.1949 - val_accuracy: 0.8983\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1559 - accuracy: 0.9431 - val_loss: 0.1944 - val_accuracy: 0.8983\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1458 - accuracy: 0.9371 - val_loss: 0.1909 - val_accuracy: 0.8983\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1529 - accuracy: 0.9375 - val_loss: 0.1926 - val_accuracy: 0.8983\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1623 - accuracy: 0.9140 - val_loss: 0.1938 - val_accuracy: 0.8983\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1531 - accuracy: 0.9239 - val_loss: 0.1894 - val_accuracy: 0.8983\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1856 - accuracy: 0.9114 - val_loss: 0.1911 - val_accuracy: 0.8983\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1744 - accuracy: 0.9180 - val_loss: 0.1903 - val_accuracy: 0.8983\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1935 - accuracy: 0.9235 - val_loss: 0.1910 - val_accuracy: 0.8983\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1701 - accuracy: 0.9035 - val_loss: 0.1973 - val_accuracy: 0.8983\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.1518 - accuracy: 0.9321 - val_loss: 0.1949 - val_accuracy: 0.8983\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1546 - accuracy: 0.9326 - val_loss: 0.1952 - val_accuracy: 0.8983\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1666 - accuracy: 0.9097 - val_loss: 0.1908 - val_accuracy: 0.8983\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.1427 - accuracy: 0.9345 - val_loss: 0.1954 - val_accuracy: 0.8983\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.1110 - accuracy: 0.9628 - val_loss: 0.1940 - val_accuracy: 0.8983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f940a14d2b0>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=16, validation_data=(x_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2fd71f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "feature = np.expand_dims(x_test[1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "06fd979e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1940 - accuracy: 0.8983\n",
      "test loss, test acc: [0.19401928782463074, 0.8983050584793091]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0ece371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 1\n",
      " 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "previsoes = model.predict(x_test)\n",
    "\n",
    "list_pre = []\n",
    "for n, i in enumerate(previsoes):\n",
    "    i = float(i)\n",
    "    if i > 0.5:\n",
    "        list_pre.append(1)\n",
    "    else:\n",
    "        list_pre.append(0)\n",
    "        \n",
    "prevs = np.array(list_pre)\n",
    "print(prevs)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "37493406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(int(previsoes[-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c9ab2bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  1]\n",
      " [ 5 20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmatrics = confusion_matrix(y_test, prevs)\n",
    "print(cmatrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f8078b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(cmatrics, index = [i for i in \"AB\"],\n",
    "                      columns = [i for i in \"AB\"])\n",
    "\n",
    "#plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442f00c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
