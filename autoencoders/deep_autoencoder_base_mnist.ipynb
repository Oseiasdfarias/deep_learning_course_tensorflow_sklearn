{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812a7c14",
   "metadata": {},
   "source": [
    "# Deep Autoencoder com a base de dados MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d56dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c0b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "(prev_train, _), (prev_test, _) = mnist.load_data()\n",
    "prev_train.shape\n",
    "\n",
    "prev_train = prev_train.astype(\"float32\") / 255\n",
    "prev_test = prev_test.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d2b23",
   "metadata": {},
   "source": [
    "### Usando o reshape para modificar a estrutura da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddbf2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_train = prev_train.reshape((len(prev_train), np.prod(prev_train.shape[1:])))\n",
    "prev_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf15ad80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_test = prev_test.reshape((len(prev_test), np.prod(prev_test.shape[1:])))\n",
    "prev_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd186e",
   "metadata": {},
   "source": [
    "# Criando o modelo Deep Autoencoder\n",
    "\n",
    "### vamos codificar os dados na sequencia\n",
    " 784 -> 128 -> 64 -> 32 <- 64 <- 128 <- 784\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f38fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87583dd9",
   "metadata": {},
   "source": [
    "## Criando o Encoder e o Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b749cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 784)               101136    \n",
      "=================================================================\n",
      "Total params: 222,384\n",
      "Trainable params: 222,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encode\n",
    "autoencoder.add(Dense(units = 128, activation = \"relu\", input_dim = 784))\n",
    "autoencoder.add(Dense(units = 64, activation = \"relu\"))\n",
    "autoencoder.add(Dense(units = 32, activation = \"relu\"))\n",
    "\n",
    "# Decode\n",
    "autoencoder.add(Dense(units = 64, activation = \"relu\"))\n",
    "autoencoder.add(Dense(units = 128, activation = \"relu\"))\n",
    "autoencoder.add(Dense(units = 784, activation = \"sigmoid\"))\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22879a56",
   "metadata": {},
   "source": [
    "## Compilando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04974745",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer = \"adam\",\n",
    "                   loss = \"binary_crossentropy\",\n",
    "                   metrics = [\"MeanAbsoluteError\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f9394",
   "metadata": {},
   "source": [
    "## Treinamento do Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e16ad7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 7s 28ms/step - loss: 0.3368 - mean_absolute_error: 0.2043 - val_loss: 0.1650 - val_mean_absolute_error: 0.0848\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.1573 - mean_absolute_error: 0.0791 - val_loss: 0.1378 - val_mean_absolute_error: 0.0656\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.1359 - mean_absolute_error: 0.0642 - val_loss: 0.1248 - val_mean_absolute_error: 0.0568\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1242 - mean_absolute_error: 0.0561 - val_loss: 0.1169 - val_mean_absolute_error: 0.0510\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1171 - mean_absolute_error: 0.0511 - val_loss: 0.1116 - val_mean_absolute_error: 0.0476\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.1117 - mean_absolute_error: 0.0474 - val_loss: 0.1078 - val_mean_absolute_error: 0.0447\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.1079 - mean_absolute_error: 0.0447 - val_loss: 0.1044 - val_mean_absolute_error: 0.0424\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 7s 29ms/step - loss: 0.1050 - mean_absolute_error: 0.0426 - val_loss: 0.1018 - val_mean_absolute_error: 0.0405\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.1026 - mean_absolute_error: 0.0408 - val_loss: 0.1000 - val_mean_absolute_error: 0.0391\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.1005 - mean_absolute_error: 0.0394 - val_loss: 0.0979 - val_mean_absolute_error: 0.0377\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.0985 - mean_absolute_error: 0.0380 - val_loss: 0.0962 - val_mean_absolute_error: 0.0365\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 7s 29ms/step - loss: 0.0972 - mean_absolute_error: 0.0370 - val_loss: 0.0954 - val_mean_absolute_error: 0.0358\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0959 - mean_absolute_error: 0.0361 - val_loss: 0.0939 - val_mean_absolute_error: 0.0348\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0946 - mean_absolute_error: 0.0352 - val_loss: 0.0930 - val_mean_absolute_error: 0.0340\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0938 - mean_absolute_error: 0.0346 - val_loss: 0.0926 - val_mean_absolute_error: 0.0338\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.0930 - mean_absolute_error: 0.0341 - val_loss: 0.0916 - val_mean_absolute_error: 0.0331\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0923 - mean_absolute_error: 0.0336 - val_loss: 0.0911 - val_mean_absolute_error: 0.0328\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0917 - mean_absolute_error: 0.0331 - val_loss: 0.0904 - val_mean_absolute_error: 0.0322\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0912 - mean_absolute_error: 0.0327 - val_loss: 0.0899 - val_mean_absolute_error: 0.0319\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0904 - mean_absolute_error: 0.0323 - val_loss: 0.0895 - val_mean_absolute_error: 0.0316\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0903 - mean_absolute_error: 0.0321 - val_loss: 0.0892 - val_mean_absolute_error: 0.0314\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0899 - mean_absolute_error: 0.0318 - val_loss: 0.0885 - val_mean_absolute_error: 0.0308\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0894 - mean_absolute_error: 0.0314 - val_loss: 0.0884 - val_mean_absolute_error: 0.0308\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0891 - mean_absolute_error: 0.0312 - val_loss: 0.0880 - val_mean_absolute_error: 0.0304\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0886 - mean_absolute_error: 0.0309 - val_loss: 0.0878 - val_mean_absolute_error: 0.0304\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0884 - mean_absolute_error: 0.0308 - val_loss: 0.0877 - val_mean_absolute_error: 0.0301\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0882 - mean_absolute_error: 0.0306 - val_loss: 0.0874 - val_mean_absolute_error: 0.0300\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0880 - mean_absolute_error: 0.0304 - val_loss: 0.0871 - val_mean_absolute_error: 0.0298\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0877 - mean_absolute_error: 0.0302 - val_loss: 0.0869 - val_mean_absolute_error: 0.0297\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0874 - mean_absolute_error: 0.0300 - val_loss: 0.0867 - val_mean_absolute_error: 0.0295\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 7s 28ms/step - loss: 0.0873 - mean_absolute_error: 0.0299 - val_loss: 0.0875 - val_mean_absolute_error: 0.0301\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0871 - mean_absolute_error: 0.0298 - val_loss: 0.0863 - val_mean_absolute_error: 0.0293\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0868 - mean_absolute_error: 0.0296 - val_loss: 0.0861 - val_mean_absolute_error: 0.0292\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.0866 - mean_absolute_error: 0.0295 - val_loss: 0.0859 - val_mean_absolute_error: 0.0290\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0866 - mean_absolute_error: 0.0295 - val_loss: 0.0857 - val_mean_absolute_error: 0.0288\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0863 - mean_absolute_error: 0.0293 - val_loss: 0.0858 - val_mean_absolute_error: 0.0289\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0860 - mean_absolute_error: 0.0291 - val_loss: 0.0859 - val_mean_absolute_error: 0.0288\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0860 - mean_absolute_error: 0.0290 - val_loss: 0.0852 - val_mean_absolute_error: 0.0284\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0855 - mean_absolute_error: 0.0287 - val_loss: 0.0849 - val_mean_absolute_error: 0.0282\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0854 - mean_absolute_error: 0.0286 - val_loss: 0.0849 - val_mean_absolute_error: 0.0282\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0855 - mean_absolute_error: 0.0286 - val_loss: 0.0847 - val_mean_absolute_error: 0.0280\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0850 - mean_absolute_error: 0.0283 - val_loss: 0.0846 - val_mean_absolute_error: 0.0281\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0849 - mean_absolute_error: 0.0283 - val_loss: 0.0841 - val_mean_absolute_error: 0.0277\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0847 - mean_absolute_error: 0.0281 - val_loss: 0.0842 - val_mean_absolute_error: 0.0277\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0845 - mean_absolute_error: 0.0280 - val_loss: 0.0839 - val_mean_absolute_error: 0.0275\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0845 - mean_absolute_error: 0.0279 - val_loss: 0.0839 - val_mean_absolute_error: 0.0276\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0843 - mean_absolute_error: 0.0278 - val_loss: 0.0837 - val_mean_absolute_error: 0.0274\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0840 - mean_absolute_error: 0.0276 - val_loss: 0.0836 - val_mean_absolute_error: 0.0274\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0839 - mean_absolute_error: 0.0275 - val_loss: 0.0833 - val_mean_absolute_error: 0.0272\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 5s 22ms/step - loss: 0.0837 - mean_absolute_error: 0.0274 - val_loss: 0.0833 - val_mean_absolute_error: 0.0271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f79fd431490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(prev_train,prev_train,\n",
    "               epochs = 50, batch_size = 256,\n",
    "               validation_data = (prev_test, prev_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51dee98",
   "metadata": {},
   "source": [
    "# Criando o Codificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86bd77e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 110,816\n",
      "Trainable params: 110,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dimensao_original = Input(shape = (784, ))\n",
    "camada_encoder1 = autoencoder.layers[0]\n",
    "camada_encoder2 = autoencoder.layers[1]\n",
    "camada_encoder3 = autoencoder.layers[2]\n",
    "\n",
    "encoder = Model(dimensao_original,\n",
    "               camada_encoder3(camada_encoder2(camada_encoder1(dimensao_original))))\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15471c05",
   "metadata": {},
   "source": [
    "### Aplicando o encoder nas imagens de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdff29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_codificadas = encoder.predict(prev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac8cf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens_codificadas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8024da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_decodificadas = autoencoder.predict(prev_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f29afa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens_decodificadas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a4c3b6",
   "metadata": {},
   "source": [
    "# Visualizando as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b549a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imagens = 10\n",
    "\n",
    "# Selecionando 10 imagens aleatórias da base de dados de teste\n",
    "imagens_test = np.random.randint(prev_test.shape[0], size = num_imagens)\n",
    "\n",
    "# Plotando as imagens\n",
    "plt.figure(figsize = (18, 18))\n",
    "\n",
    "for i, indice_img in enumerate(imagens_test):\n",
    "    \n",
    "    # Gráfico 01, plotar a imagem Original\n",
    "    eixo = plt.subplot(10, 10, i + 1)\n",
    "    plt.imshow(prev_test[indice_img].reshape(28, 28))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "     # Gráfico 02, plotar a imagem codificada\n",
    "    eixo = plt.subplot(10, 10, i + 1 + num_imagens)\n",
    "    plt.imshow(imagens_code[indice_img].reshape(8, 4))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    # Gráfico 03, plotar a imagem Decodificada\n",
    "    eixo = plt.subplot(10, 10, i + 1 + num_imagens * 2)\n",
    "    plt.imshow(imagens_decode[indice_img].reshape(28, 28))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
