{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5be97801",
   "metadata": {},
   "source": [
    "# Classificação binária - base breast cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc143916",
   "metadata": {},
   "source": [
    "### Carregamento dos dados utilizando o pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "567cc506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "previsores = pd.read_csv(\"./entradas_breast.csv\")\n",
    "classe = pd.read_csv(\"./saidas_breast.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb68de",
   "metadata": {},
   "source": [
    "## Dividindo os dados em base de treinamento e base de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48fef64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2266ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_train, prev_test, class_train, class_test = train_test_split(previsores, classe, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c287f9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6133a673",
   "metadata": {},
   "source": [
    "## Criando o modelo de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9640232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b2fd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = Sequential()\n",
    "\n",
    "# Camada de entrada dos dados previsores\n",
    "classificador.add(Dense(units = 16, activation = \"relu\", \n",
    "                            kernel_initializer = \"random_uniform\", input_dim = 30))\n",
    "# Camada de Dropout\n",
    "classificador.add(Dropout(0.15))\n",
    "\n",
    "# Primeira camada oculta da rede neural\n",
    "classificador.add(Dense(units = 16, activation = \"relu\", \n",
    "                            kernel_initializer = \"random_uniform\"))\n",
    "\n",
    "# Camada de Dropout para a camada oculta 1\n",
    "classificador.add(Dropout(0.15))\n",
    "\n",
    "# Segunda camada oculta da rede neural\n",
    "classificador.add(Dense(units = 16, activation = \"relu\", \n",
    "                            kernel_initializer = \"random_uniform\"))\n",
    "# Camada de Dropout para a segunda camada oculta\n",
    "classificador.add(Dropout(0.15))\n",
    "\n",
    "# Camada de saida da rede neural, como a rede tem como objetivo identificar se a pessoa tem ou não câncer\n",
    "# podemos aplicar uma saida binária, de forma que, quanto mais proximo de 0 a saida estiver, maior a probabilidade\n",
    "# de que a pessoas não esteja com câncer, e quanto maior for a proximodade de 1, significa uma maior probabilidade\n",
    "# de que a pessoa esteja com câncer \"\"\"\n",
    "classificador.add(Dense(units = 1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef41853",
   "metadata": {},
   "source": [
    "## Compilando o modelo para o treinamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcfbff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,057\n",
      "Trainable params: 1,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# otimizador = keras.optimizers.Adam(lr = 0.001, decay = 0.0001, clipvalue = 0.2)\n",
    "# classificador.compile(optimizer = otimizador, loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\"])\n",
    "\n",
    "classificador.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"binary_accuracy\"])\n",
    "classificador.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52861a45",
   "metadata": {},
   "source": [
    "## Iniciando o treinamento da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36ce2ba9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "43/43 [==============================] - 1s 3ms/step - loss: 0.6974 - binary_accuracy: 0.5205\n",
      "Epoch 2/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5785 - binary_accuracy: 0.6646\n",
      "Epoch 3/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5303 - binary_accuracy: 0.6911\n",
      "Epoch 4/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5021 - binary_accuracy: 0.7491\n",
      "Epoch 5/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4313 - binary_accuracy: 0.8106\n",
      "Epoch 6/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5145 - binary_accuracy: 0.7459\n",
      "Epoch 7/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3632 - binary_accuracy: 0.8683\n",
      "Epoch 8/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4020 - binary_accuracy: 0.8507\n",
      "Epoch 9/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3693 - binary_accuracy: 0.8619\n",
      "Epoch 10/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3756 - binary_accuracy: 0.8651\n",
      "Epoch 11/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3546 - binary_accuracy: 0.8539\n",
      "Epoch 12/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3835 - binary_accuracy: 0.8551\n",
      "Epoch 13/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3022 - binary_accuracy: 0.8843\n",
      "Epoch 14/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2938 - binary_accuracy: 0.8860\n",
      "Epoch 15/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2512 - binary_accuracy: 0.9072\n",
      "Epoch 16/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2696 - binary_accuracy: 0.8933\n",
      "Epoch 17/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2422 - binary_accuracy: 0.9234\n",
      "Epoch 18/400\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2517 - binary_accuracy: 0.8931\n",
      "Epoch 19/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1938 - binary_accuracy: 0.9224\n",
      "Epoch 20/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2462 - binary_accuracy: 0.8908\n",
      "Epoch 21/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2539 - binary_accuracy: 0.8914\n",
      "Epoch 22/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2261 - binary_accuracy: 0.9228\n",
      "Epoch 23/400\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2859 - binary_accuracy: 0.8937\n",
      "Epoch 24/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2417 - binary_accuracy: 0.9138\n",
      "Epoch 25/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2352 - binary_accuracy: 0.9023\n",
      "Epoch 26/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2893 - binary_accuracy: 0.8781\n",
      "Epoch 27/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2800 - binary_accuracy: 0.8939\n",
      "Epoch 28/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2218 - binary_accuracy: 0.9095\n",
      "Epoch 29/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2019 - binary_accuracy: 0.9253\n",
      "Epoch 30/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2416 - binary_accuracy: 0.9127\n",
      "Epoch 31/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2328 - binary_accuracy: 0.9082\n",
      "Epoch 32/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2427 - binary_accuracy: 0.8989\n",
      "Epoch 33/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2029 - binary_accuracy: 0.9049\n",
      "Epoch 34/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2327 - binary_accuracy: 0.9142\n",
      "Epoch 35/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1901 - binary_accuracy: 0.9311\n",
      "Epoch 36/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2395 - binary_accuracy: 0.9130\n",
      "Epoch 37/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2326 - binary_accuracy: 0.9153\n",
      "Epoch 38/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2108 - binary_accuracy: 0.9059\n",
      "Epoch 39/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2176 - binary_accuracy: 0.9096\n",
      "Epoch 40/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2848 - binary_accuracy: 0.8968\n",
      "Epoch 41/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2247 - binary_accuracy: 0.9012\n",
      "Epoch 42/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1810 - binary_accuracy: 0.9383\n",
      "Epoch 43/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1854 - binary_accuracy: 0.9261\n",
      "Epoch 44/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1910 - binary_accuracy: 0.9335\n",
      "Epoch 45/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1823 - binary_accuracy: 0.9317\n",
      "Epoch 46/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2173 - binary_accuracy: 0.9073\n",
      "Epoch 47/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2080 - binary_accuracy: 0.9091\n",
      "Epoch 48/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2510 - binary_accuracy: 0.8739\n",
      "Epoch 49/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2095 - binary_accuracy: 0.9190\n",
      "Epoch 50/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2440 - binary_accuracy: 0.9123\n",
      "Epoch 51/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1713 - binary_accuracy: 0.9334\n",
      "Epoch 52/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1527 - binary_accuracy: 0.9449\n",
      "Epoch 53/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2004 - binary_accuracy: 0.9276\n",
      "Epoch 54/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1743 - binary_accuracy: 0.9391\n",
      "Epoch 55/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2415 - binary_accuracy: 0.9081\n",
      "Epoch 56/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2031 - binary_accuracy: 0.9328\n",
      "Epoch 57/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1982 - binary_accuracy: 0.9081\n",
      "Epoch 58/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2040 - binary_accuracy: 0.9372\n",
      "Epoch 59/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2089 - binary_accuracy: 0.9311\n",
      "Epoch 60/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1878 - binary_accuracy: 0.9312\n",
      "Epoch 61/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2425 - binary_accuracy: 0.9005\n",
      "Epoch 62/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1579 - binary_accuracy: 0.9319\n",
      "Epoch 63/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1903 - binary_accuracy: 0.9270\n",
      "Epoch 64/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1714 - binary_accuracy: 0.9285\n",
      "Epoch 65/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1584 - binary_accuracy: 0.9366\n",
      "Epoch 66/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1900 - binary_accuracy: 0.9179\n",
      "Epoch 67/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1843 - binary_accuracy: 0.9415\n",
      "Epoch 68/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2010 - binary_accuracy: 0.9083\n",
      "Epoch 69/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1714 - binary_accuracy: 0.9344\n",
      "Epoch 70/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1815 - binary_accuracy: 0.9331\n",
      "Epoch 71/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1615 - binary_accuracy: 0.9292\n",
      "Epoch 72/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1895 - binary_accuracy: 0.9227\n",
      "Epoch 73/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2068 - binary_accuracy: 0.9221\n",
      "Epoch 74/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1638 - binary_accuracy: 0.9356\n",
      "Epoch 75/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2550 - binary_accuracy: 0.8975\n",
      "Epoch 76/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1866 - binary_accuracy: 0.9177\n",
      "Epoch 77/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1479 - binary_accuracy: 0.9424\n",
      "Epoch 78/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1843 - binary_accuracy: 0.9288\n",
      "Epoch 79/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1683 - binary_accuracy: 0.9285\n",
      "Epoch 80/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2012 - binary_accuracy: 0.9214\n",
      "Epoch 81/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1746 - binary_accuracy: 0.9378\n",
      "Epoch 82/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2404 - binary_accuracy: 0.9028\n",
      "Epoch 83/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2058 - binary_accuracy: 0.9220\n",
      "Epoch 84/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2013 - binary_accuracy: 0.9023\n",
      "Epoch 85/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1881 - binary_accuracy: 0.9292\n",
      "Epoch 86/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1666 - binary_accuracy: 0.9370\n",
      "Epoch 87/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1156 - binary_accuracy: 0.9454\n",
      "Epoch 88/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1640 - binary_accuracy: 0.9364\n",
      "Epoch 89/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1812 - binary_accuracy: 0.9484\n",
      "Epoch 90/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1703 - binary_accuracy: 0.9482\n",
      "Epoch 91/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2077 - binary_accuracy: 0.9130\n",
      "Epoch 92/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1627 - binary_accuracy: 0.9520\n",
      "Epoch 93/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1778 - binary_accuracy: 0.9405\n",
      "Epoch 94/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1562 - binary_accuracy: 0.9342\n",
      "Epoch 95/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1814 - binary_accuracy: 0.9210\n",
      "Epoch 96/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1662 - binary_accuracy: 0.9372\n",
      "Epoch 97/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1556 - binary_accuracy: 0.9384\n",
      "Epoch 98/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1419 - binary_accuracy: 0.9376\n",
      "Epoch 99/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1751 - binary_accuracy: 0.9312\n",
      "Epoch 100/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2171 - binary_accuracy: 0.9175\n",
      "Epoch 101/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1667 - binary_accuracy: 0.9462\n",
      "Epoch 102/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1307 - binary_accuracy: 0.9484\n",
      "Epoch 103/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1419 - binary_accuracy: 0.9388\n",
      "Epoch 104/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1895 - binary_accuracy: 0.9209\n",
      "Epoch 105/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1442 - binary_accuracy: 0.9511\n",
      "Epoch 106/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1806 - binary_accuracy: 0.9328\n",
      "Epoch 107/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1598 - binary_accuracy: 0.9394\n",
      "Epoch 108/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1691 - binary_accuracy: 0.9227\n",
      "Epoch 109/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1965 - binary_accuracy: 0.9124\n",
      "Epoch 110/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1726 - binary_accuracy: 0.9315\n",
      "Epoch 111/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1812 - binary_accuracy: 0.9133\n",
      "Epoch 112/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1918 - binary_accuracy: 0.9283\n",
      "Epoch 113/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1726 - binary_accuracy: 0.9240\n",
      "Epoch 114/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1064 - binary_accuracy: 0.9676\n",
      "Epoch 115/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1175 - binary_accuracy: 0.9476\n",
      "Epoch 116/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1239 - binary_accuracy: 0.9497\n",
      "Epoch 117/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1654 - binary_accuracy: 0.9331\n",
      "Epoch 118/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1605 - binary_accuracy: 0.9440\n",
      "Epoch 119/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1809 - binary_accuracy: 0.9361\n",
      "Epoch 120/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1953 - binary_accuracy: 0.9253\n",
      "Epoch 121/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1316 - binary_accuracy: 0.9548\n",
      "Epoch 122/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1327 - binary_accuracy: 0.9619\n",
      "Epoch 123/400\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1705 - binary_accuracy: 0.9261\n",
      "Epoch 124/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1108 - binary_accuracy: 0.9560\n",
      "Epoch 125/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1249 - binary_accuracy: 0.9394\n",
      "Epoch 126/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1552 - binary_accuracy: 0.9304\n",
      "Epoch 127/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1882 - binary_accuracy: 0.9088\n",
      "Epoch 128/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1564 - binary_accuracy: 0.9363\n",
      "Epoch 129/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1746 - binary_accuracy: 0.9278\n",
      "Epoch 130/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1515 - binary_accuracy: 0.9535\n",
      "Epoch 131/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1670 - binary_accuracy: 0.9235\n",
      "Epoch 132/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1806 - binary_accuracy: 0.9145\n",
      "Epoch 133/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1424 - binary_accuracy: 0.9502\n",
      "Epoch 134/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0925 - binary_accuracy: 0.9673\n",
      "Epoch 135/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1356 - binary_accuracy: 0.9468\n",
      "Epoch 136/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1391 - binary_accuracy: 0.9464\n",
      "Epoch 137/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1457 - binary_accuracy: 0.9333\n",
      "Epoch 138/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1562 - binary_accuracy: 0.9246\n",
      "Epoch 139/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1337 - binary_accuracy: 0.9435\n",
      "Epoch 140/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1613 - binary_accuracy: 0.9278\n",
      "Epoch 141/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1825 - binary_accuracy: 0.9327\n",
      "Epoch 142/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1133 - binary_accuracy: 0.9518\n",
      "Epoch 143/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1523 - binary_accuracy: 0.9298\n",
      "Epoch 144/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1700 - binary_accuracy: 0.9286\n",
      "Epoch 145/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1404 - binary_accuracy: 0.9474\n",
      "Epoch 146/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1316 - binary_accuracy: 0.9513\n",
      "Epoch 147/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1458 - binary_accuracy: 0.9335\n",
      "Epoch 148/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1411 - binary_accuracy: 0.9542\n",
      "Epoch 149/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1561 - binary_accuracy: 0.9443\n",
      "Epoch 150/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1137 - binary_accuracy: 0.9501\n",
      "Epoch 151/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1566 - binary_accuracy: 0.9488\n",
      "Epoch 152/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1448 - binary_accuracy: 0.9373\n",
      "Epoch 153/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1333 - binary_accuracy: 0.9513\n",
      "Epoch 154/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1969 - binary_accuracy: 0.9227\n",
      "Epoch 155/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1369 - binary_accuracy: 0.9327\n",
      "Epoch 156/400\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1561 - binary_accuracy: 0.9250\n",
      "Epoch 157/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1211 - binary_accuracy: 0.9635\n",
      "Epoch 158/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1470 - binary_accuracy: 0.9416\n",
      "Epoch 159/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1754 - binary_accuracy: 0.9421\n",
      "Epoch 160/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1488 - binary_accuracy: 0.9414\n",
      "Epoch 161/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1665 - binary_accuracy: 0.9180\n",
      "Epoch 162/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1771 - binary_accuracy: 0.9203\n",
      "Epoch 163/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1385 - binary_accuracy: 0.9449\n",
      "Epoch 164/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1272 - binary_accuracy: 0.9343\n",
      "Epoch 165/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1390 - binary_accuracy: 0.9363\n",
      "Epoch 166/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1188 - binary_accuracy: 0.9485\n",
      "Epoch 167/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1824 - binary_accuracy: 0.9192\n",
      "Epoch 168/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1548 - binary_accuracy: 0.9340\n",
      "Epoch 169/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1424 - binary_accuracy: 0.9489\n",
      "Epoch 170/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1244 - binary_accuracy: 0.9482\n",
      "Epoch 171/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1721 - binary_accuracy: 0.9225\n",
      "Epoch 172/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1926 - binary_accuracy: 0.9270\n",
      "Epoch 173/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1369 - binary_accuracy: 0.9363\n",
      "Epoch 174/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1322 - binary_accuracy: 0.9518\n",
      "Epoch 175/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1577 - binary_accuracy: 0.9360\n",
      "Epoch 176/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1728 - binary_accuracy: 0.9287\n",
      "Epoch 177/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1886 - binary_accuracy: 0.9073\n",
      "Epoch 178/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1377 - binary_accuracy: 0.9416\n",
      "Epoch 179/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1536 - binary_accuracy: 0.9442\n",
      "Epoch 180/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1268 - binary_accuracy: 0.9504\n",
      "Epoch 181/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1596 - binary_accuracy: 0.9448\n",
      "Epoch 182/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1271 - binary_accuracy: 0.9424\n",
      "Epoch 183/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1205 - binary_accuracy: 0.9607\n",
      "Epoch 184/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1262 - binary_accuracy: 0.9484\n",
      "Epoch 185/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1859 - binary_accuracy: 0.9134\n",
      "Epoch 186/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1911 - binary_accuracy: 0.9026\n",
      "Epoch 187/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1200 - binary_accuracy: 0.9495\n",
      "Epoch 188/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2077 - binary_accuracy: 0.9118\n",
      "Epoch 189/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1754 - binary_accuracy: 0.9276\n",
      "Epoch 190/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1441 - binary_accuracy: 0.9466\n",
      "Epoch 191/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1639 - binary_accuracy: 0.9350\n",
      "Epoch 192/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1372 - binary_accuracy: 0.9439\n",
      "Epoch 193/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1405 - binary_accuracy: 0.9501\n",
      "Epoch 194/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1775 - binary_accuracy: 0.9262\n",
      "Epoch 195/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1449 - binary_accuracy: 0.9614\n",
      "Epoch 196/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1925 - binary_accuracy: 0.9258\n",
      "Epoch 197/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1684 - binary_accuracy: 0.9099\n",
      "Epoch 198/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1753 - binary_accuracy: 0.9227\n",
      "Epoch 199/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1682 - binary_accuracy: 0.9297\n",
      "Epoch 200/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1693 - binary_accuracy: 0.9238\n",
      "Epoch 201/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1376 - binary_accuracy: 0.9654\n",
      "Epoch 202/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1274 - binary_accuracy: 0.9364\n",
      "Epoch 203/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1213 - binary_accuracy: 0.9536\n",
      "Epoch 204/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1323 - binary_accuracy: 0.9453\n",
      "Epoch 205/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1153 - binary_accuracy: 0.9690\n",
      "Epoch 206/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1445 - binary_accuracy: 0.9377\n",
      "Epoch 207/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1007 - binary_accuracy: 0.9666\n",
      "Epoch 208/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1955 - binary_accuracy: 0.9224\n",
      "Epoch 209/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1065 - binary_accuracy: 0.9617\n",
      "Epoch 210/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1384 - binary_accuracy: 0.9204\n",
      "Epoch 211/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1615 - binary_accuracy: 0.9210\n",
      "Epoch 212/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1375 - binary_accuracy: 0.9502\n",
      "Epoch 213/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1780 - binary_accuracy: 0.9133\n",
      "Epoch 214/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1529 - binary_accuracy: 0.9277\n",
      "Epoch 215/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1338 - binary_accuracy: 0.9391\n",
      "Epoch 216/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1850 - binary_accuracy: 0.9354\n",
      "Epoch 217/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2079 - binary_accuracy: 0.9262\n",
      "Epoch 218/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1916 - binary_accuracy: 0.9037\n",
      "Epoch 219/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1332 - binary_accuracy: 0.9434\n",
      "Epoch 220/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1412 - binary_accuracy: 0.9544\n",
      "Epoch 221/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1534 - binary_accuracy: 0.9462\n",
      "Epoch 222/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1465 - binary_accuracy: 0.9459\n",
      "Epoch 223/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1257 - binary_accuracy: 0.9477\n",
      "Epoch 224/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1273 - binary_accuracy: 0.9525\n",
      "Epoch 225/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1238 - binary_accuracy: 0.9574\n",
      "Epoch 226/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0929 - binary_accuracy: 0.9667\n",
      "Epoch 227/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0932 - binary_accuracy: 0.9634\n",
      "Epoch 228/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1272 - binary_accuracy: 0.9398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1355 - binary_accuracy: 0.9410\n",
      "Epoch 230/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1660 - binary_accuracy: 0.9278\n",
      "Epoch 231/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1793 - binary_accuracy: 0.9286\n",
      "Epoch 232/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1339 - binary_accuracy: 0.9334\n",
      "Epoch 233/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1444 - binary_accuracy: 0.9302\n",
      "Epoch 234/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2051 - binary_accuracy: 0.9186\n",
      "Epoch 235/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1343 - binary_accuracy: 0.9513\n",
      "Epoch 236/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1692 - binary_accuracy: 0.9316A: 0s - loss: 0.1860 - binary_accuracy: 0.92\n",
      "Epoch 237/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1152 - binary_accuracy: 0.9599\n",
      "Epoch 238/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1099 - binary_accuracy: 0.9620\n",
      "Epoch 239/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1939 - binary_accuracy: 0.9267\n",
      "Epoch 240/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1523 - binary_accuracy: 0.9517\n",
      "Epoch 241/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1940 - binary_accuracy: 0.9324\n",
      "Epoch 242/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2017 - binary_accuracy: 0.9203\n",
      "Epoch 243/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1158 - binary_accuracy: 0.9629\n",
      "Epoch 244/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1474 - binary_accuracy: 0.9430\n",
      "Epoch 245/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1460 - binary_accuracy: 0.9306\n",
      "Epoch 246/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1190 - binary_accuracy: 0.9630\n",
      "Epoch 247/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1436 - binary_accuracy: 0.9325\n",
      "Epoch 248/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1533 - binary_accuracy: 0.9387\n",
      "Epoch 249/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1236 - binary_accuracy: 0.9510\n",
      "Epoch 250/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1294 - binary_accuracy: 0.9411\n",
      "Epoch 251/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1476 - binary_accuracy: 0.9400\n",
      "Epoch 252/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1165 - binary_accuracy: 0.9558\n",
      "Epoch 253/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1257 - binary_accuracy: 0.9534\n",
      "Epoch 254/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1412 - binary_accuracy: 0.9292\n",
      "Epoch 255/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1113 - binary_accuracy: 0.9571\n",
      "Epoch 256/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1078 - binary_accuracy: 0.9529\n",
      "Epoch 257/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1163 - binary_accuracy: 0.9629\n",
      "Epoch 258/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1384 - binary_accuracy: 0.9360\n",
      "Epoch 259/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1589 - binary_accuracy: 0.9354\n",
      "Epoch 260/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1156 - binary_accuracy: 0.9556\n",
      "Epoch 261/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1605 - binary_accuracy: 0.9381\n",
      "Epoch 262/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1474 - binary_accuracy: 0.9517\n",
      "Epoch 263/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1418 - binary_accuracy: 0.9393\n",
      "Epoch 264/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1272 - binary_accuracy: 0.9518\n",
      "Epoch 265/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1398 - binary_accuracy: 0.9354\n",
      "Epoch 266/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1480 - binary_accuracy: 0.9448\n",
      "Epoch 267/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1482 - binary_accuracy: 0.9467\n",
      "Epoch 268/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1761 - binary_accuracy: 0.9445\n",
      "Epoch 269/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1984 - binary_accuracy: 0.9343\n",
      "Epoch 270/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2216 - binary_accuracy: 0.9217\n",
      "Epoch 271/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1544 - binary_accuracy: 0.9404\n",
      "Epoch 272/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2093 - binary_accuracy: 0.9234\n",
      "Epoch 273/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1736 - binary_accuracy: 0.9120\n",
      "Epoch 274/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1902 - binary_accuracy: 0.9223\n",
      "Epoch 275/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1769 - binary_accuracy: 0.9215\n",
      "Epoch 276/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2316 - binary_accuracy: 0.8992\n",
      "Epoch 277/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1006 - binary_accuracy: 0.9558\n",
      "Epoch 278/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2012 - binary_accuracy: 0.9366\n",
      "Epoch 279/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1345 - binary_accuracy: 0.9448\n",
      "Epoch 280/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1056 - binary_accuracy: 0.9609\n",
      "Epoch 281/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1045 - binary_accuracy: 0.9598\n",
      "Epoch 282/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1256 - binary_accuracy: 0.9485\n",
      "Epoch 283/400\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1343 - binary_accuracy: 0.9490\n",
      "Epoch 284/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1333 - binary_accuracy: 0.9359\n",
      "Epoch 285/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1324 - binary_accuracy: 0.9491\n",
      "Epoch 286/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1681 - binary_accuracy: 0.9327\n",
      "Epoch 287/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1837 - binary_accuracy: 0.9105\n",
      "Epoch 288/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1732 - binary_accuracy: 0.9350\n",
      "Epoch 289/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1067 - binary_accuracy: 0.9542\n",
      "Epoch 290/400\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1418 - binary_accuracy: 0.9486\n",
      "Epoch 291/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1728 - binary_accuracy: 0.9304\n",
      "Epoch 292/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1200 - binary_accuracy: 0.9599\n",
      "Epoch 293/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1686 - binary_accuracy: 0.9355\n",
      "Epoch 294/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1438 - binary_accuracy: 0.9464\n",
      "Epoch 295/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1073 - binary_accuracy: 0.9487\n",
      "Epoch 296/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2017 - binary_accuracy: 0.9282\n",
      "Epoch 297/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1804 - binary_accuracy: 0.9265\n",
      "Epoch 298/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1766 - binary_accuracy: 0.9449\n",
      "Epoch 299/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1551 - binary_accuracy: 0.9314\n",
      "Epoch 300/400\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1419 - binary_accuracy: 0.9487\n",
      "Epoch 301/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1134 - binary_accuracy: 0.9534\n",
      "Epoch 302/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1529 - binary_accuracy: 0.9319\n",
      "Epoch 303/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1310 - binary_accuracy: 0.9456\n",
      "Epoch 304/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1441 - binary_accuracy: 0.9233\n",
      "Epoch 305/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1359 - binary_accuracy: 0.9452\n",
      "Epoch 306/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1138 - binary_accuracy: 0.9668\n",
      "Epoch 307/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2090 - binary_accuracy: 0.9258\n",
      "Epoch 308/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1428 - binary_accuracy: 0.9591\n",
      "Epoch 309/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1246 - binary_accuracy: 0.9513\n",
      "Epoch 310/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1370 - binary_accuracy: 0.9467\n",
      "Epoch 311/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1372 - binary_accuracy: 0.9543\n",
      "Epoch 312/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1773 - binary_accuracy: 0.9419\n",
      "Epoch 313/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1739 - binary_accuracy: 0.9350\n",
      "Epoch 314/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1340 - binary_accuracy: 0.9537\n",
      "Epoch 315/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1375 - binary_accuracy: 0.9459\n",
      "Epoch 316/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1683 - binary_accuracy: 0.9362\n",
      "Epoch 317/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1316 - binary_accuracy: 0.9519\n",
      "Epoch 318/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1331 - binary_accuracy: 0.9544\n",
      "Epoch 319/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1840 - binary_accuracy: 0.9249\n",
      "Epoch 320/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2100 - binary_accuracy: 0.9097\n",
      "Epoch 321/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1954 - binary_accuracy: 0.9347\n",
      "Epoch 322/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1439 - binary_accuracy: 0.9364\n",
      "Epoch 323/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1659 - binary_accuracy: 0.9148\n",
      "Epoch 324/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1324 - binary_accuracy: 0.9495\n",
      "Epoch 325/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1442 - binary_accuracy: 0.9587\n",
      "Epoch 326/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1691 - binary_accuracy: 0.9411\n",
      "Epoch 327/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1434 - binary_accuracy: 0.9409\n",
      "Epoch 328/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1679 - binary_accuracy: 0.9386\n",
      "Epoch 329/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1281 - binary_accuracy: 0.9490\n",
      "Epoch 330/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1203 - binary_accuracy: 0.9573\n",
      "Epoch 331/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1105 - binary_accuracy: 0.9611\n",
      "Epoch 332/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1314 - binary_accuracy: 0.9414\n",
      "Epoch 333/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1674 - binary_accuracy: 0.9376\n",
      "Epoch 334/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1020 - binary_accuracy: 0.9581\n",
      "Epoch 335/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1104 - binary_accuracy: 0.9443\n",
      "Epoch 336/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1336 - binary_accuracy: 0.9585\n",
      "Epoch 337/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1875 - binary_accuracy: 0.9391\n",
      "Epoch 338/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1341 - binary_accuracy: 0.9632\n",
      "Epoch 339/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1421 - binary_accuracy: 0.9336\n",
      "Epoch 340/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1387 - binary_accuracy: 0.9525\n",
      "Epoch 341/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1495 - binary_accuracy: 0.9389\n",
      "Epoch 342/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1246 - binary_accuracy: 0.9519\n",
      "Epoch 343/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1076 - binary_accuracy: 0.9644\n",
      "Epoch 344/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0929 - binary_accuracy: 0.9715\n",
      "Epoch 345/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1248 - binary_accuracy: 0.9479\n",
      "Epoch 346/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1900 - binary_accuracy: 0.9354\n",
      "Epoch 347/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1388 - binary_accuracy: 0.9470\n",
      "Epoch 348/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1042 - binary_accuracy: 0.9614\n",
      "Epoch 349/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1769 - binary_accuracy: 0.9239\n",
      "Epoch 350/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1407 - binary_accuracy: 0.9465\n",
      "Epoch 351/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1704 - binary_accuracy: 0.9153\n",
      "Epoch 352/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1300 - binary_accuracy: 0.9388\n",
      "Epoch 353/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1441 - binary_accuracy: 0.9534\n",
      "Epoch 354/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1249 - binary_accuracy: 0.9477\n",
      "Epoch 355/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1300 - binary_accuracy: 0.9372\n",
      "Epoch 356/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1026 - binary_accuracy: 0.9568\n",
      "Epoch 357/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1696 - binary_accuracy: 0.9458\n",
      "Epoch 358/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1502 - binary_accuracy: 0.9460\n",
      "Epoch 359/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1251 - binary_accuracy: 0.9473\n",
      "Epoch 360/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1302 - binary_accuracy: 0.9478\n",
      "Epoch 361/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0915 - binary_accuracy: 0.9690\n",
      "Epoch 362/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1629 - binary_accuracy: 0.9242\n",
      "Epoch 363/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1164 - binary_accuracy: 0.9504\n",
      "Epoch 364/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1578 - binary_accuracy: 0.9456\n",
      "Epoch 365/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1378 - binary_accuracy: 0.9448\n",
      "Epoch 366/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1356 - binary_accuracy: 0.9482\n",
      "Epoch 367/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1077 - binary_accuracy: 0.9520\n",
      "Epoch 368/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1627 - binary_accuracy: 0.9354\n",
      "Epoch 369/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0979 - binary_accuracy: 0.9635\n",
      "Epoch 370/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1315 - binary_accuracy: 0.9419\n",
      "Epoch 371/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1384 - binary_accuracy: 0.9408\n",
      "Epoch 372/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1336 - binary_accuracy: 0.9450\n",
      "Epoch 373/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1467 - binary_accuracy: 0.9366\n",
      "Epoch 374/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1641 - binary_accuracy: 0.9335\n",
      "Epoch 375/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1266 - binary_accuracy: 0.9555\n",
      "Epoch 376/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1399 - binary_accuracy: 0.9461\n",
      "Epoch 377/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1706 - binary_accuracy: 0.9327\n",
      "Epoch 378/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1540 - binary_accuracy: 0.9311\n",
      "Epoch 379/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1420 - binary_accuracy: 0.9369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/400\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1091 - binary_accuracy: 0.9507\n",
      "Epoch 381/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1327 - binary_accuracy: 0.9375\n",
      "Epoch 382/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1006 - binary_accuracy: 0.9661\n",
      "Epoch 383/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1522 - binary_accuracy: 0.9475\n",
      "Epoch 384/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1214 - binary_accuracy: 0.9587\n",
      "Epoch 385/400\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1195 - binary_accuracy: 0.9552\n",
      "Epoch 386/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1207 - binary_accuracy: 0.9561\n",
      "Epoch 387/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1224 - binary_accuracy: 0.9461\n",
      "Epoch 388/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1370 - binary_accuracy: 0.9559\n",
      "Epoch 389/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1181 - binary_accuracy: 0.9634\n",
      "Epoch 390/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1039 - binary_accuracy: 0.9537\n",
      "Epoch 391/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1602 - binary_accuracy: 0.9244\n",
      "Epoch 392/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1131 - binary_accuracy: 0.9524\n",
      "Epoch 393/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1162 - binary_accuracy: 0.9479\n",
      "Epoch 394/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1243 - binary_accuracy: 0.9401\n",
      "Epoch 395/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1731 - binary_accuracy: 0.9274\n",
      "Epoch 396/400\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1200 - binary_accuracy: 0.9616\n",
      "Epoch 397/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1489 - binary_accuracy: 0.9461\n",
      "Epoch 398/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1086 - binary_accuracy: 0.9607\n",
      "Epoch 399/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1342 - binary_accuracy: 0.9485\n",
      "Epoch 400/400\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1107 - binary_accuracy: 0.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa512b30970>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(prev_train, class_train, batch_size = 10, epochs = 400, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f087fd8",
   "metadata": {},
   "source": [
    "## Visualizando os pesos da rede neural "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ce1ca",
   "metadata": {},
   "source": [
    "### Camada oculta 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8760458f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 5.11446921e-03, -4.94292170e-01, -2.15341151e-02,\n",
      "        -4.31766361e-01,  1.12954890e-02,  6.97669992e-03,\n",
      "         5.80334030e-02,  2.90279984e-01,  1.03566989e-01,\n",
      "        -3.24173942e-02,  7.36529082e-02, -6.01484299e-01,\n",
      "        -4.15405594e-02,  1.71832904e-01,  6.79283664e-02,\n",
      "        -7.84370244e-01],\n",
      "       [ 4.03253501e-03,  8.73170644e-02, -4.44401279e-02,\n",
      "         1.33864716e-01,  2.42148712e-02,  9.12921280e-02,\n",
      "         1.86146259e-01, -1.29555002e-01,  1.30872399e-01,\n",
      "         6.91392273e-02,  9.18628424e-02, -1.02272287e-01,\n",
      "        -7.13331252e-02, -1.02360427e-01,  6.56787818e-03,\n",
      "        -9.12482589e-02],\n",
      "       [ 4.56767203e-03, -5.99553585e-01,  4.92416788e-04,\n",
      "        -5.26530445e-01, -3.02231312e-02, -1.57836135e-02,\n",
      "         1.46066174e-01,  3.68654072e-01,  1.57468587e-01,\n",
      "         3.55040766e-02,  1.14587620e-01, -4.75089878e-01,\n",
      "        -1.81240402e-02,  2.85975009e-01,  8.75367671e-02,\n",
      "        -5.85482121e-01],\n",
      "       [-3.89062241e-02, -7.22299069e-02, -5.25384173e-02,\n",
      "        -6.86165839e-02, -8.69049504e-03, -1.33816019e-01,\n",
      "        -3.32702994e-02,  1.01422697e-01, -5.78636304e-02,\n",
      "        -2.03050058e-02, -5.30869998e-02, -7.89673775e-02,\n",
      "        -7.49373510e-02,  9.52381492e-02, -6.64301738e-02,\n",
      "        -8.15001577e-02],\n",
      "       [ 1.40046899e-03,  3.22377563e-01,  6.58083661e-03,\n",
      "         1.83649883e-01,  2.00864505e-02,  2.01325282e-01,\n",
      "        -2.59370450e-02, -3.83574590e-02,  4.08834755e-01,\n",
      "         1.07030673e-02,  5.90820462e-02,  3.96754712e-01,\n",
      "         4.77414997e-03,  3.10618039e-02,  5.29494882e-02,\n",
      "        -8.36823732e-02],\n",
      "       [-6.89320192e-02, -1.98205754e-01, -3.84110734e-02,\n",
      "        -4.70557660e-02,  1.29014170e-02,  2.51381174e-02,\n",
      "        -3.78723629e-02,  2.22125798e-01,  2.46246513e-02,\n",
      "         3.93453054e-02, -7.85917118e-02,  1.54988438e-01,\n",
      "        -6.29253685e-03,  3.63274693e-01, -9.85860229e-02,\n",
      "         1.11054610e-02],\n",
      "       [ 4.21291143e-02, -3.67662489e-01,  1.99767780e-02,\n",
      "         1.37491494e-01, -8.16498771e-02,  1.72248825e-01,\n",
      "        -3.52736041e-02, -8.37983657e-03,  3.99244316e-02,\n",
      "         1.24043515e-02,  1.17532328e-01,  1.95454314e-01,\n",
      "         1.53476847e-02,  5.25946952e-02,  1.83475614e-01,\n",
      "        -1.04795925e-01],\n",
      "       [-1.70297492e-02, -1.18174879e-02,  3.87683436e-02,\n",
      "        -2.53472120e-01,  2.73828730e-02,  7.69861639e-01,\n",
      "        -9.66842845e-02,  1.39676422e-01,  1.17567383e-01,\n",
      "        -8.41490328e-02,  4.73651886e-01,  1.06454261e-01,\n",
      "         6.71448708e-02,  1.82240773e-02,  3.64966214e-01,\n",
      "         1.55675635e-01],\n",
      "       [ 1.32116526e-02, -5.82851544e-02, -1.72442738e-02,\n",
      "         7.75759481e-03,  1.39827589e-02,  8.57004762e-01,\n",
      "         1.79698840e-01,  1.82565570e-01, -9.83761698e-02,\n",
      "        -3.02125253e-02,  7.30725706e-01,  3.43554839e-02,\n",
      "         1.61212229e-03, -3.45326662e-02,  1.22976601e-02,\n",
      "         8.51225108e-02],\n",
      "       [ 4.25537750e-02,  1.38494680e-02, -5.24968579e-02,\n",
      "        -9.30141732e-02, -3.41060571e-02, -3.31383944e-01,\n",
      "         3.32326680e-01,  1.33056200e+00, -3.10695559e-01,\n",
      "        -1.65515393e-02, -2.86954373e-01,  1.45736977e-01,\n",
      "        -3.81015949e-02,  5.26193917e-01, -2.40588576e-01,\n",
      "        -3.10783327e-01],\n",
      "       [ 1.62638947e-02,  1.50916558e-02,  3.89399789e-02,\n",
      "        -1.18139639e-01, -5.64091541e-02, -1.41945541e-01,\n",
      "         3.97863984e-02, -3.21221091e-02, -2.31587817e-03,\n",
      "        -1.02119166e-02, -1.48946509e-01,  3.96741703e-02,\n",
      "        -7.74239516e-03, -1.38163567e-01, -1.34613603e-01,\n",
      "         4.24289964e-02],\n",
      "       [ 2.58217496e-03,  2.25869892e-03, -4.31272155e-03,\n",
      "         7.82557856e-03,  2.99495016e-03,  1.31658390e-01,\n",
      "        -3.14904563e-02, -4.33876216e-02,  2.15690322e-02,\n",
      "        -1.19535308e-02,  9.25618634e-02, -1.04490556e-02,\n",
      "        -1.15943952e-02, -9.84747410e-02,  2.02180017e-02,\n",
      "        -1.43219586e-04],\n",
      "       [-3.19826901e-02,  7.99254701e-03, -3.42354700e-02,\n",
      "        -3.65580572e-03, -8.95829313e-03, -1.23570506e-02,\n",
      "        -3.33312899e-02, -3.43948556e-03, -3.76888141e-02,\n",
      "        -6.12544594e-03, -2.16904879e-02, -1.83263477e-02,\n",
      "        -1.12767341e-02, -8.16029869e-03, -6.32892316e-03,\n",
      "         7.17715267e-03],\n",
      "       [-3.77695635e-02,  1.09840751e-01, -3.26960832e-02,\n",
      "         2.16882266e-02, -1.21867126e-02, -2.70463854e-01,\n",
      "         6.40748963e-02,  5.87543026e-02, -4.56229806e-01,\n",
      "         9.09608975e-02, -2.41779402e-01, -1.49683403e-02,\n",
      "         1.25403747e-01,  5.56215495e-02,  9.60169882e-02,\n",
      "        -1.24964081e-02],\n",
      "       [-7.92908855e-03,  5.72654009e-01, -4.77303639e-02,\n",
      "         8.29045057e-01,  3.89900990e-02,  2.12383159e-02,\n",
      "         2.11485773e-01, -7.04888552e-02,  6.66803718e-02,\n",
      "        -3.12571530e-03,  1.27200320e-01,  1.98938295e-01,\n",
      "         3.11533711e-03, -1.57691151e-01,  3.88727970e-02,\n",
      "         4.91658747e-02],\n",
      "       [ 1.42132118e-02, -6.36987865e-01,  2.50216313e-02,\n",
      "        -3.01858723e-01,  9.82966349e-02,  9.82246637e-01,\n",
      "        -1.08882822e-01, -1.77241728e-01,  9.24809813e-01,\n",
      "        -4.03726008e-03,  9.00451362e-01, -1.14853010e-01,\n",
      "        -1.89165194e-02, -2.86344856e-01,  3.88972282e-01,\n",
      "         1.62463188e-01],\n",
      "       [ 2.10783053e-02,  7.51807451e-01,  1.94682945e-02,\n",
      "        -5.28523207e-01, -4.31455933e-02, -3.23047787e-01,\n",
      "         5.04604459e-01,  4.72406074e-02,  4.89504427e-01,\n",
      "         5.84066696e-02,  2.23840505e-01, -7.35916257e-01,\n",
      "        -3.19805928e-02, -7.95248896e-02,  8.16057622e-02,\n",
      "        -4.62098390e-01],\n",
      "       [ 1.48775866e-02,  5.02069771e-01, -4.58859392e-02,\n",
      "        -2.72020519e-01,  6.32015020e-02, -2.82321960e-01,\n",
      "         1.95387661e-01,  1.25037420e+00, -2.35619307e-01,\n",
      "         2.16980861e-03, -2.73722470e-01,  4.15487796e-01,\n",
      "        -3.26617286e-02,  9.11648095e-01, -1.53905347e-01,\n",
      "         3.72617841e-01],\n",
      "       [-1.40015995e-02,  6.43995106e-01, -4.68381979e-02,\n",
      "        -1.07652538e-01, -6.66449815e-02,  2.77925245e-02,\n",
      "         1.29556492e-01,  4.01153296e-01, -3.54125619e-01,\n",
      "         4.41667885e-02, -1.30391065e-02, -3.99110138e-01,\n",
      "        -7.60663161e-03,  8.06896746e-01, -1.81938961e-01,\n",
      "        -1.33888379e-01],\n",
      "       [-7.38755334e-03,  1.04640985e+00, -2.81224493e-02,\n",
      "         9.82201755e-01, -5.05712144e-02, -1.72746912e-01,\n",
      "         1.28046885e-01, -2.30726063e-01, -2.21142396e-01,\n",
      "         3.32268560e-03, -2.88528711e-01,  7.52698720e-01,\n",
      "        -7.52844941e-03, -1.54323339e-01, -3.51132601e-01,\n",
      "         6.25145614e-01],\n",
      "       [ 2.58461647e-02, -4.82614875e-01,  2.50009783e-02,\n",
      "        -4.46117908e-01,  4.83807400e-02, -2.69552786e-03,\n",
      "         3.75523604e-02,  2.30368048e-01,  6.47896677e-02,\n",
      "         3.13418859e-04,  2.14591138e-02, -4.76042897e-01,\n",
      "         1.83821656e-02,  9.92957130e-02,  3.72783281e-02,\n",
      "        -6.21307433e-01],\n",
      "       [-1.34933926e-02,  4.69976306e-01, -1.08251600e-02,\n",
      "         5.49013197e-01,  1.92671064e-02, -1.19305365e-01,\n",
      "         7.07703605e-02, -2.83165306e-01, -2.54146475e-02,\n",
      "         1.42306825e-02, -1.15724713e-01,  2.97237691e-02,\n",
      "        -6.50707483e-02, -2.13381618e-01, -5.00196554e-02,\n",
      "         1.57012135e-01],\n",
      "       [-2.39969194e-02, -2.98018128e-01,  1.90818552e-02,\n",
      "        -3.55669230e-01, -1.60964150e-02, -3.17388363e-02,\n",
      "         4.86860871e-02,  2.23792523e-01,  8.77487436e-02,\n",
      "        -1.92180015e-02,  1.16527900e-02, -3.52406114e-01,\n",
      "        -9.90893040e-03,  1.63427547e-01,  2.09456999e-02,\n",
      "        -4.02995259e-01],\n",
      "       [-1.71846133e-02,  1.71164766e-01, -5.24472445e-02,\n",
      "         1.90623477e-01, -1.31958425e-02, -1.86159983e-01,\n",
      "        -1.10541776e-01, -1.89159930e-01, -1.47246093e-01,\n",
      "        -3.06246579e-02, -2.05184937e-01,  2.03616068e-01,\n",
      "        -2.79711857e-02, -1.82282463e-01, -1.81078181e-01,\n",
      "         1.81415290e-01],\n",
      "       [-6.05986118e-02,  3.81571092e-02,  2.60072164e-02,\n",
      "         4.34567519e-02, -2.30148435e-02,  9.04912502e-02,\n",
      "         2.51314312e-01,  3.26647043e-01, -2.29576007e-01,\n",
      "        -1.71166321e-03,  1.85565930e-03, -4.13505845e-02,\n",
      "         6.62943395e-03,  4.08345491e-01, -1.74452662e-01,\n",
      "         3.72312078e-03],\n",
      "       [-5.10586984e-02, -2.35862240e-01,  3.58282626e-02,\n",
      "        -6.37546480e-02,  8.32346603e-02,  3.78810674e-01,\n",
      "        -4.42195237e-02, -4.69854027e-02,  2.05525339e-01,\n",
      "         2.19570585e-02,  2.40947202e-01,  1.09031796e-01,\n",
      "        -2.95870323e-02,  3.79447229e-02,  1.84105590e-01,\n",
      "         3.61966975e-02],\n",
      "       [ 9.61617939e-03, -2.75934577e-01,  1.93677172e-02,\n",
      "        -7.51532465e-02, -2.54298560e-02, -2.32664675e-01,\n",
      "         9.69267040e-02,  4.31762403e-03,  3.71335983e-01,\n",
      "         6.78352593e-03, -2.44291514e-01,  2.16683038e-02,\n",
      "         5.67677319e-02,  1.60497632e-02,  9.29090008e-02,\n",
      "         5.68321869e-02],\n",
      "       [-2.40412820e-03, -1.06134407e-01, -8.58751684e-03,\n",
      "         1.49801597e-02, -7.23744929e-02,  1.40771702e-01,\n",
      "        -6.62996620e-02, -1.00051217e-01, -3.60041976e-01,\n",
      "         8.88879299e-02, -3.78127098e-02,  3.50777119e-01,\n",
      "        -4.01922464e-02,  2.62508780e-01, -2.99949199e-02,\n",
      "         1.77737564e-01],\n",
      "       [ 6.22266456e-02, -9.93618462e-03, -1.67146809e-02,\n",
      "        -1.16096977e-02, -1.11003388e-02,  3.15397531e-02,\n",
      "         3.87328923e-01, -1.34541571e-01,  3.28593880e-01,\n",
      "        -2.94155348e-03, -4.29199897e-02, -8.84686708e-02,\n",
      "        -5.19806482e-02, -1.20607533e-01, -1.12334117e-01,\n",
      "         6.34013563e-02],\n",
      "       [-4.38876003e-02,  8.37315977e-01,  3.92249413e-03,\n",
      "         8.31012964e-01, -1.19199194e-02, -2.64901131e-01,\n",
      "        -1.25222072e-01, -2.23862141e-01, -3.00835848e-01,\n",
      "         1.54199218e-02, -2.91944772e-01,  8.09483707e-01,\n",
      "         3.91490534e-02, -2.07496285e-01, -2.47983158e-01,\n",
      "         7.32185185e-01]], dtype=float32), array([-0.01247831, -1.2919023 , -0.00326918, -1.180148  ,  0.01084398,\n",
      "        0.17573366,  0.3064966 ,  0.6758929 ,  0.3591683 ,  0.03902699,\n",
      "        0.29666337, -0.99926454, -0.0333519 ,  0.47935355,  0.2732348 ,\n",
      "       -1.2685083 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "peso0 = classificador.layers[0].get_weights()\n",
    "print(peso0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1a8c6",
   "metadata": {},
   "source": [
    "### Canada oculta 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "990675f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "peso1 = classificador.layers[1].get_weights()\n",
    "print(peso1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30138bb1",
   "metadata": {},
   "source": [
    "### Canada oculta 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4f6709f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.01921269, -0.05284457, -0.01885863, -0.01583299,  0.08147161,\n",
      "        -0.01690102,  0.02994005, -0.00440214,  0.0905507 ,  0.08944226,\n",
      "         0.02449   ,  0.12366331,  0.05814687, -0.00752915, -0.00526084,\n",
      "         0.0341792 ],\n",
      "       [-0.01456685,  0.06048276, -0.17027967,  0.07306912, -0.06872034,\n",
      "        -0.2700424 , -0.07920475, -0.05365692, -0.02607652, -0.05163281,\n",
      "        -0.02401853, -0.02163882, -0.0698511 ,  0.06013135,  0.05883088,\n",
      "         0.07197282],\n",
      "       [ 0.01624052, -0.00176037, -0.03920852, -0.02258326, -0.00973903,\n",
      "         0.00245325,  0.02021413,  0.0274966 ,  0.01580951, -0.00061941,\n",
      "         0.04772485, -0.01790103, -0.00216343, -0.06466725,  0.0436132 ,\n",
      "        -0.04107284],\n",
      "       [-0.14360029,  0.05955457, -0.11705546, -0.02966908, -0.06076344,\n",
      "         0.07350577, -0.10911663, -0.13420612, -0.15591119, -0.08998171,\n",
      "        -0.12527181, -0.11393396, -0.09756968, -0.00454807,  0.07239289,\n",
      "         0.07232454],\n",
      "       [-0.0090416 , -0.00449949, -0.02563114,  0.03720467,  0.01723615,\n",
      "         0.00776572,  0.01772506, -0.03046771,  0.03805633,  0.03792687,\n",
      "        -0.02037318,  0.03575742, -0.05129753, -0.03248309, -0.00776708,\n",
      "         0.00768546],\n",
      "       [ 0.14435694, -0.21464397,  0.26455054, -0.09607458,  0.0268852 ,\n",
      "        -0.10991532,  0.01000476,  0.11796334,  0.10940298,  0.11904532,\n",
      "        -0.03628222,  0.07574555,  0.03644307, -0.1297438 , -0.2730879 ,\n",
      "        -0.12276954],\n",
      "       [ 0.07831249, -0.04726182,  0.18152398, -0.03585302,  0.06874468,\n",
      "        -0.01393679,  0.03836825,  0.21174055,  0.08362107,  0.07415044,\n",
      "         0.14064582,  0.12648751,  0.14281301,  0.0063841 , -0.05100439,\n",
      "        -0.04530611],\n",
      "       [ 0.06466451, -0.0590673 ,  0.04029167, -0.03230907,  0.11091544,\n",
      "         0.05829844,  0.00689257,  0.13844651,  0.08582179,  0.06919905,\n",
      "         0.09297527,  0.05982742,  0.11991348, -0.09239067, -0.03972365,\n",
      "        -0.01770986],\n",
      "       [ 0.01663641, -0.16248932,  0.0803496 , -0.04316016, -0.0165069 ,\n",
      "        -0.07321559, -0.04412479,  0.04956871,  0.0205843 ,  0.0407076 ,\n",
      "         0.03834439,  0.07783718,  0.06620042, -0.01893709, -0.00679794,\n",
      "        -0.05314181],\n",
      "       [ 0.03513816, -0.02774685,  0.041744  , -0.03530103,  0.13443664,\n",
      "        -0.05955381, -0.05907957,  0.0571574 ,  0.0370951 ,  0.10508146,\n",
      "         0.04569843,  0.06612302,  0.0297427 , -0.0345267 , -0.02392103,\n",
      "        -0.10978176],\n",
      "       [ 0.11249993, -0.1091031 ,  0.19342305, -0.14975643,  0.02291716,\n",
      "        -0.19764388,  0.01673415,  0.13173582,  0.01893002,  0.04850152,\n",
      "        -0.00209079,  0.14371991,  0.09391332, -0.11716026, -0.19777532,\n",
      "        -0.00725605],\n",
      "       [-0.16875406,  0.11445925, -0.13815168,  0.10027775, -0.18311153,\n",
      "         0.09495877,  0.08798537, -0.13143076,  0.00542   , -0.1328449 ,\n",
      "         0.00748391, -0.00830367, -0.1719851 ,  0.14211409,  0.12652275,\n",
      "         0.2884424 ],\n",
      "       [ 0.02196637, -0.06927477,  0.03291897, -0.06532728,  0.06505433,\n",
      "        -0.0322849 , -0.01121349,  0.14659041, -0.00883793,  0.13257955,\n",
      "         0.00082712,  0.08641683, -0.00241405, -0.07460473, -0.02165468,\n",
      "        -0.05576684],\n",
      "       [ 0.04822357, -0.0564404 ,  0.09987941,  0.0210674 ,  0.09753705,\n",
      "        -0.09110605, -0.00909657,  0.07193715,  0.08747736,  0.1226356 ,\n",
      "         0.07927886,  0.07358078,  0.16482288,  0.06611748,  0.01908412,\n",
      "        -0.09669848],\n",
      "       [-0.02631324, -0.11377142,  0.11972325, -0.03708709,  0.1772271 ,\n",
      "        -0.09694155, -0.00097855,  0.01697911,  0.02877038,  0.00680022,\n",
      "        -0.00355474, -0.00771475,  0.10107117, -0.03203977, -0.04994141,\n",
      "        -0.05795006],\n",
      "       [-0.14197525, -0.00847838, -0.14471807,  0.05115368, -0.13160644,\n",
      "         0.04216373,  0.07040878, -0.13406175, -0.13635649, -0.06023109,\n",
      "        -0.1161517 , -0.15571652, -0.06175329,  0.10674136,  0.04711344,\n",
      "         0.08251955]], dtype=float32), array([ 0.7039267 , -0.8270927 ,  0.14222534, -0.87855   ,  0.1838081 ,\n",
      "       -0.4906326 ,  0.5298258 ,  0.38641733,  0.77132815,  0.7259942 ,\n",
      "        0.6644087 ,  0.6916588 ,  0.59102273, -0.69736755, -0.85733026,\n",
      "       -0.75597394], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "peso2 = classificador.layers[2].get_weights()\n",
    "print(peso2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36cea23",
   "metadata": {},
   "source": [
    "### Validando o resultado com o dataset de teste utilizando o próprio Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2efe8975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7095 - binary_accuracy: 0.9161\n",
      "\n",
      "test loss, test acc: [0.709515392780304, 0.9160839319229126]\n"
     ]
    }
   ],
   "source": [
    "results = classificador.evaluate(prev_test, class_test)\n",
    "print(\"\\ntest loss, test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b6d67c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsões:  [[0.7297466 ]\n",
      " [0.99959064]\n",
      " [0.01221105]\n",
      " [0.93549526]]\n",
      "Valor da Classe prevista:       0\n",
      "190  0\n",
      "169  1\n",
      "105  0\n",
      "39   0\n"
     ]
    }
   ],
   "source": [
    "previsoes = classificador.predict(prev_test[54:58])\n",
    "print(\"Previsões: \", previsoes)\n",
    "vreal = class_test[54:58]\n",
    "print(\"Valor da Classe prevista: \", vreal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a831e",
   "metadata": {},
   "source": [
    "### Validando o resultado com o dataset de teste com auxílio do Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b566a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = classificador.predict(prev_test)\n",
    "previsoes = (previsoes > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e8993a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8741258741258742\n"
     ]
    }
   ],
   "source": [
    "precisao = accuracy_score(class_test, previsoes)\n",
    "print(precisao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce9463",
   "metadata": {},
   "source": [
    "## Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b615c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "742b0f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37 11]\n",
      " [ 7 88]]\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(class_test, previsoes)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a31aa77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(matrix, index = [i for i in \"AB\"],\n",
    "                  columns = [i for i in \"AB\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3587eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
